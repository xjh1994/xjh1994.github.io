---
author: xjh1994
comments: true
date: 2013-07-05 10:22:44+00:00
layout: post
slug: '%e7%a8%8b%e5%ba%8f%e5%91%98%e7%9a%84%e9%87%8e%e5%bf%83%ef%bc%9a%e8%ae%a9gpu%e5%83%8fcpu%e4%b8%80%e6%a0%b7%e8%bf%90%e8%a1%8c'
title: 程序员的野心：让GPU像CPU一样运行
wordpress_id: 304
categories:
- 创意
- 未分类
- 硬件
- 编程
- 趣闻轶事
tags:
- CPU
- GPU
- 硬件
---

GPU代表的是图形处理单元，但是，这些小小芯片除了处理图形功能，还有其它用处。比如，Google使用GPU来为人脑建模，Salesforce则依赖GPU分析Twitter微博数据流。GPU很适合并行处理运算，也就是同时执行成千上万个任务。怎么做呢？你得开发一个新软件，让它挖掘GPU芯片的潜力。**最近美国印第安纳大学计算机博士埃里克-浩克（Eric Holk）就作出尝试，他开发了一个应用程序来运行GPU。浩克说：“GPU编程仍然需要程序员管理许多低层细节，这些细节是与GPU执行的主要任务分离 的。我们想开发一个系统，帮助程序员管理这些细节，让GPU在提高生产力的同时仍然有很好的性能。”**






[![http://static.cnbetacdn.com/newsimg/2013/0705/01372976770.jpg_w600.jpg](http://static.cnbetacdn.com/newsimg/2013/0705/01372976770.jpg_w600.jpg)](http://static.cnbetacdn.com/newsimg/2013/0705/01372976770.jpg)



一般来说，电脑计算任务大多由CPU完成。一个CPU处理一个计算序列，也就是所谓的一次处理一个线程，它必须尽可能快地执行。GPU的设计初衷是一次处理多个线程，这些线程处理速度慢很多，但程序可以利用并行优势执行得更快一些，就像超级电脑一样。



浩克称，今天，CPU已经能执行并行运算了，多核也很流行，但它们主要还是针对单线程优化的。



GPU术语直到1999年才出现，但在此之前已经有早期的视频处理芯片了，它们于1970-1980年推出。当时，视频处理芯片严重依赖CPU进行图形处理，1990年代图形显卡更流行了，也更强大了，主要是因为3D显卡出现。



乔治亚科技大学克里斯-麦克拉纳罕（Chris McClanahan）认为，GPU硬件架构已经进化，以前它只是特定单一核心，现在向一组高并行、可编程核心转变，它可以用来处理更通用的计算。毫无疑 问，随着GPU技术的发展，它会增加更多可编程性、更多并行性，变得越来越像CPU，可以用于通用计算。麦克拉纳罕说，CPU和GPU最终会融合。同时， 开发者也开始挖掘GPU的能力，用于不同的应用中，包括物理系统建模、强化智能手机等。



浩克解释道：“GPU的内存带宽也比CPU高很多，在对海量数据进行简单计算时，它的效率更好。”



已经有一些GPU编程语言存在，包括CUDA和OpenCL。汉克开发了新语言Harlan，它可以控制GPU。实际上，Harlan被编译成 OpenCL。但与其它语言不同，Harlan语言的抽象思维更多与高级编程语言相近，比如Python、Ruby。浩克称：“Harlan的另一个目标 是想回答一个问题：如果从一开始就开发一门语言，它最初的目标就是支持GPU编程，那会怎样呢？目前的大多系统将GPU编程嵌入到现有语言中，开发者不得 不处理旧语言的所有问题。Harlan可以让开发者更好地为目标硬件、程序作决策。”

Harlan语法基于Scheme，它是Lisp语言的现代变种，Scheme是所有好语言的始祖。为了让编程语言更“正常”一些，浩克还用到 了Rust语言，这种语言主要面向开发系统，它可以操作硬件底层。浩克的目的是让程序员编写的代码更有效，因为Harlan能生产更好的GPU代码。

![http://static.cnbetacdn.com/newsimg/2013/0705/11372976770.png](http://static.cnbetacdn.com/newsimg/2013/0705/11372976770.png)


